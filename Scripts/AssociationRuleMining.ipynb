{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daf6d227-7087-4a42-89ba-66ed5149a70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import copy\n",
    "import math\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "765a20e6-ab90-4521-8c32-1c8ffd3e088e",
   "metadata": {},
   "outputs": [],
   "source": [
    "item1 = [\"pen\",\"ink\",\"diary\",\"soap\"]\n",
    "item2 = [\"pen\",\"ink\",\"diary\"]\n",
    "item3 = [\"pen\",\"diary\"]\n",
    "item4 = [\"pen\",\"ink\",\"soap\"]\n",
    "\n",
    "example_df = pd.DataFrame([item1,item2,item3,item4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "880580a9-6c71-4cf1-93e5-6c7218c1f590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pen</td>\n",
       "      <td>ink</td>\n",
       "      <td>diary</td>\n",
       "      <td>soap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pen</td>\n",
       "      <td>ink</td>\n",
       "      <td>diary</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pen</td>\n",
       "      <td>diary</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pen</td>\n",
       "      <td>ink</td>\n",
       "      <td>soap</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0      1      2     3\n",
       "0  pen    ink  diary  soap\n",
       "1  pen    ink  diary  None\n",
       "2  pen  diary   None  None\n",
       "3  pen    ink   soap  None"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06f7f2af-682f-4734-8c17-adc740d65cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateFirstPassCandidate(df, minsup):\n",
    "    \n",
    "    n = len(df)\n",
    "    ctr = {}\n",
    "    for i in range(n):\n",
    "        row =  list(df.values[i])\n",
    "        for entry in row:\n",
    "            if entry != '' and entry!= None and entry!=\"nan\" and not pd.isna(entry):\n",
    "                ctr[tuple([entry])] = ctr.get(tuple([entry]),0) + 1\n",
    "    \n",
    "    candidateSet = []\n",
    "    for key in ctr:\n",
    "        if (ctr[key]/n) >= minsup:\n",
    "            candidateSet.append(key)\n",
    "            \n",
    "    return sorted(candidateSet),ctr\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87880e7d-5bf9-4b6d-9c8b-f240123866ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('diary',), ('ink',), ('pen',)],\n",
       " {('pen',): 4, ('ink',): 3, ('diary',): 3, ('soap',): 2})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generateFirstPassCandidate(example_df,0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50fd537b-d6d3-459b-b7f9-3bd3ead95638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateCandidateSet(lprev):\n",
    "    # lprev is a set of len k-1 \n",
    "    candidateSet = []\n",
    "    \n",
    "    n = len(lprev)\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(i+1,n):\n",
    "            if lprev[i][:-1] == lprev[j][:-1] and lprev[i][-1] < lprev[j][-1]:\n",
    "                candidateSet.append(lprev[i]+tuple([lprev[j][-1]]))\n",
    "    \n",
    "    candidateSet = pruneCandidateSet(candidateSet,lprev)\n",
    "    \n",
    "    return candidateSet\n",
    "             \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "995413d2-f335-464f-8097-0cd244ebc3e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('diary', 'ink'), ('diary', 'pen'), ('ink', 'pen')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generateCandidateSet([('diary',), ('ink',), ('pen',)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "432c9dfe-9c4d-4d6c-a28c-16e978a045c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pruneCandidateSet(candidateSets, lprev):\n",
    "    # prunning set to remove such sets from candidate sets which posses a k-1 length subset that is not part of lprev\n",
    "    prunnedCandidateSet = []\n",
    "    \n",
    "    for candidateSet in candidateSets:\n",
    "        # generating all the subset os candidateSet with k-1 length\n",
    "        allSubset = [] # all subsets of k-1 length\n",
    "        n = len(candidateSet)\n",
    "        \n",
    "        for i in range(n):\n",
    "            allSubset.append(candidateSet[:i]+candidateSet[i+1:])\n",
    "        \n",
    "        # if any one of the k-1 length subset is missing we don't included the candidateSet\n",
    "        \n",
    "        include = True\n",
    "        for subset in allSubset:\n",
    "            if subset not in lprev:\n",
    "                include = False\n",
    "                break\n",
    "        \n",
    "        if include:\n",
    "            prunnedCandidateSet.append(candidateSet)\n",
    "        \n",
    "        \n",
    "    \n",
    "    return prunnedCandidateSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07172ac6-3623-44e5-8641-d6fb09f699fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('diary', 'ink'), ('diary', 'pen'), ('ink', 'pen')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruneCandidateSet([('diary', 'ink'), ('diary', 'pen'), ('ink', 'pen')],[('diary',), ('ink',), ('pen',)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a545f1fd-8757-43bd-91e0-0ad1c6174459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to filter rows which match the values in the list\n",
    "def match_all(row, match_list):\n",
    "    return all(value in row.values for value in match_list)\n",
    "\n",
    "def generateLargeItemSet(df, minSup):\n",
    "    largeItemSet = []   \n",
    "    \n",
    "    dataSet = df.values\n",
    "    \n",
    "    n = len(dataSet)\n",
    "    \n",
    "    # Add an optimization to reduce the df size each time, no need to do a complete scan\n",
    "    \n",
    "    lprev,counter = generateFirstPassCandidate(df, minSup)\n",
    "    largeItemSet = largeItemSet + lprev\n",
    "    \n",
    "    while lprev:\n",
    "        candidateSet = generateCandidateSet(lprev)\n",
    "        lnext = []\n",
    "        cur_df=pd.DataFrame()\n",
    "        for entry in candidateSet:\n",
    "            print(entry)\n",
    "#             tempDf = df.isin(list(entry))\n",
    "#             print(df)\n",
    "            tempDf = df[df.apply(lambda row: match_all(row, list(entry)), axis=1)]\n",
    "            count=len(tempDf)\n",
    "#             print(tempDf)\n",
    "#             print(tempDf)\n",
    "#             resPerRow = (tempDf.values+0).sum(1)\n",
    "#             print(resPerRow)\n",
    "#             n1 = len(entry)\n",
    "#             count = sum(i >= n1 for i in resPerRow)\n",
    "            \n",
    "            counter[entry] = count\n",
    "            \n",
    "            if count/n >= minSup:\n",
    "                lnext.append(entry)\n",
    "                cur_df=pd.concat([cur_df, tempDf]).drop_duplicates();\n",
    "                \n",
    "        \n",
    "        if lnext:\n",
    "            largeItemSet = largeItemSet + lnext\n",
    "            \n",
    "        lprev = copy.copy(lnext)\n",
    "        df=cur_df;\n",
    "    \n",
    "    return largeItemSet,counter\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f08cc476-e4ff-4b5c-8a6b-cbfec361137d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('diary', 'ink')\n",
      "     0      1      2     3\n",
      "0  pen    ink  diary  soap\n",
      "1  pen    ink  diary  None\n",
      "2  pen  diary   None  None\n",
      "3  pen    ink   soap  None\n",
      "     0    1      2     3\n",
      "0  pen  ink  diary  soap\n",
      "1  pen  ink  diary  None\n",
      "('diary', 'pen')\n",
      "     0      1      2     3\n",
      "0  pen    ink  diary  soap\n",
      "1  pen    ink  diary  None\n",
      "2  pen  diary   None  None\n",
      "3  pen    ink   soap  None\n",
      "     0      1      2     3\n",
      "0  pen    ink  diary  soap\n",
      "1  pen    ink  diary  None\n",
      "2  pen  diary   None  None\n",
      "('ink', 'pen')\n",
      "     0      1      2     3\n",
      "0  pen    ink  diary  soap\n",
      "1  pen    ink  diary  None\n",
      "2  pen  diary   None  None\n",
      "3  pen    ink   soap  None\n",
      "     0    1      2     3\n",
      "0  pen  ink  diary  soap\n",
      "1  pen  ink  diary  None\n",
      "3  pen  ink   soap  None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([('diary',), ('ink',), ('pen',), ('diary', 'pen'), ('ink', 'pen')],\n",
       " {('pen',): 4,\n",
       "  ('ink',): 3,\n",
       "  ('diary',): 3,\n",
       "  ('soap',): 2,\n",
       "  ('diary', 'ink'): 2,\n",
       "  ('diary', 'pen'): 3,\n",
       "  ('ink', 'pen'): 3})"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generateLargeItemSet(example_df, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dbed1e60-563d-451f-bff5-90074bc926ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateAssociationRules(largeItemSet,counter,minConf):\n",
    "    # All the items in largeItemSet have sufficent support we need to find assoication rules from large itemsets such that they have good confidence\n",
    "    associationRule = [] # tuples (LHS,RHS,confidence)\n",
    "    for itemSet in largeItemSet:\n",
    "        \n",
    "        n = len(itemSet)\n",
    "        \n",
    "        for i in range(1,n):\n",
    "            LHS = itemSet[:i]\n",
    "            RHS = itemSet[i:]\n",
    "            \n",
    "            # For rule LHS -> RHS\n",
    "            conf1 = counter[itemSet]/counter[LHS]\n",
    "            if conf1 >= minConf:\n",
    "                associationRule.append((LHS,RHS,conf1))\n",
    "            \n",
    "            # For rule RHS -> LHS\n",
    "            conf2  = counter[itemSet]/counter[RHS]\n",
    "                    \n",
    "            if conf2 >= minConf:\n",
    "                associationRule.append((RHS,LHS,conf2))\n",
    "    \n",
    "    return associationRule\n",
    "            \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6573a6d7-ce04-49c9-ae27-c710d7a8455b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0      1      2     3\n",
      "0  pen    ink  diary  soap\n",
      "1  pen    ink  diary  None\n",
      "2  pen  diary   None  None\n",
      "3  pen    ink   soap  None\n",
      "2\n",
      "     0    1      2     3\n",
      "0  pen  ink  diary  soap\n",
      "1  pen  ink  diary  None\n",
      "     0      1      2     3\n",
      "0  pen    ink  diary  soap\n",
      "1  pen    ink  diary  None\n",
      "2  pen  diary   None  None\n",
      "3  pen    ink   soap  None\n",
      "3\n",
      "     0      1      2     3\n",
      "0  pen    ink  diary  soap\n",
      "1  pen    ink  diary  None\n",
      "2  pen  diary   None  None\n",
      "     0      1      2     3\n",
      "0  pen    ink  diary  soap\n",
      "1  pen    ink  diary  None\n",
      "2  pen  diary   None  None\n",
      "3  pen    ink   soap  None\n",
      "3\n",
      "     0    1      2     3\n",
      "0  pen  ink  diary  soap\n",
      "1  pen  ink  diary  None\n",
      "3  pen  ink   soap  None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('diary',), ('pen',), 1.0), (('ink',), ('pen',), 1.0)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "largeItemSet,counter = generateLargeItemSet(example_df, 0.7)\n",
    "generateAssociationRules(largeItemSet,counter,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80764d53-228f-4249-baa1-e624f46c7b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(fileName,minSup,minConf,outputFile = \"output.txt\"):\n",
    "    df = pd.read_csv(fileName,dtype=str)\n",
    "    n = len(df)\n",
    "    \n",
    "    df = df.apply(lambda x: pd.Series(x,dtype=str).drop_duplicates(), axis=1) # Removing Duplicate values from the Row and replacing the duplicates with Nan\n",
    "\n",
    "    largeItemSet,counter = generateLargeItemSet(df, minSup)\n",
    "    \n",
    "    f = open(outputFile, 'w')\n",
    "    \n",
    "    largeItemSet.sort(key = lambda x : counter[x],reverse = True)\n",
    "    \n",
    "    \n",
    "    f.write(\"==Frequent itemsets (min_sup=\"+ str(minSup*100) + \"%) \\n\")\n",
    "    for itemSet in largeItemSet:\n",
    "        json.dump(list(itemSet),f)\n",
    "        f.write(\",\" + str((counter[itemSet]/n)*100) + \"% \\n\" )\n",
    "    \n",
    "    rules = generateAssociationRules(largeItemSet,counter,minConf)\n",
    "    \n",
    "    rules.sort(key = lambda x: x[2] , reverse = True)\n",
    "    f.write(\"==High-confidence association rules (min_conf=\"+ str(minConf*100) + \"%) \\n\")\n",
    "    for rule in rules:\n",
    "        json.dump(list(rule[0]),f)\n",
    "        f.write(\" => \")\n",
    "        json.dump(list(rule[1]),f)\n",
    "        f.write(\" (Conf: \" + str(rule[2]*100) + \"%, Supp: \" + str((counter[itemSet]/n)*100) + \"%) \\n\")\n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fa4e73aa-c53f-4fd9-aa2e-e7207f46c3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"example.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1c2bd5b3-aab2-4cee-bdff-0c7de02283f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "main(\"example.csv\",0.7,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1bee688c-3613-4a9e-bc71-9b0a9cfd6cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "main(\"./INTEGRATED-DATASET-SMALL.csv\",0.01,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f19b900-305e-4fd6-9b49-5f1874e1cb96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
